<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 雨宮 新 research website</title>
    <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/</link>
    <description>Recent content in Posts on 雨宮 新 research website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Mar 2020 23:00:00 +0900</lastBuildDate>
    
	<atom:link href="https://aamemiya.github.io/webpage_aamemiya/jp/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>「ファスト＆スロー」</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/200323/</link>
      <pubDate>Mon, 23 Mar 2020 23:00:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/200323/</guid>
      <description>ファスト＆スロー あなたの意思はどのように決まるか
(原題 &amp;ldquo;Thinking, Fast and Slow&amp;rdquo;)
ダニエル・カーネマン著、村井章子訳　ハヤカワ・ノンフィクション文庫
意思決定に関わる心理学の名著で、「人間の思考はいかに単純な統計学の結論と一致しない決断を導くか」ということを様々な側面から例証し分析している、様々な分野で話題になることの多い本である。
骨子となるのは「二つのシステム」の導入である。すなわち、人間の思考においては二つの異なるシステムが働いており、それぞれ直感的な判断を司る「ファスト」な思考（システム１）と、論理的な熟考を担当する「スロー」な思考（システム２）に対応する。（これらのシステムの定義については、筆者自身が説明のための操作的な道具にすぎないと述べている。すなわち脳内の物理的な実体と対応するかどうかは問題にしていない。）
システム１は情報を認識し、処理し、判断することを短時間のうちに少ない労力で行うことに特化している。画像や言語の認識、簡単な算数、連想、推論や予測まで、システム１は実にいろいろなことをこなしている。こうしたことを迅速に行えることは、予想外のことが常に起こり得る自然環境の中で生存するのために獲得した、人間に限らず生き物に共通した能力である。しかしそれゆえに、システム１が自動的に行う判断が統計的・論理的な正しさとは一致しない場合がある。我々がときどき直面している問題において論理的には決して正当でない判断を気付かないうちに行ってしまうのは、そのようなシステム１の誤りのためである。この種の誤りを「ヒューリスティックバイアス」と呼ぶ。
本書の大部分は、様々なタイプのヒューリスティックバイアスの紹介からなる。各章では巧妙な思考実験が数多く紹介されており、普段気付かないヒューリスティックバイアスの働きにどれだけ我々の思考が引きずられているかを実感できるようになっている。簡単な質問に対して自分の出した「直感的な」答えが、後の統計的考察によっていかに非合理的なものだったか明らかになる。さらに、それが説明された後でさえも、問題文を見直すたびに非合理な答えを出そうとするシステム１が変わらずに働き続けていることに気付かされることになる。
重要なのは、この「ファスト」なシステム１が全く努力を必要としない、自動的な働きであるということにある。システム２が集中力を発揮して意識して働かせる必要があるのに対し、システム１は普段意識して動かすことも、動いていることに気付くこともない。また、勝手に動いているシステム１の働きを止めることもできない。したがって、ヒューリスティックバイアスは我々の意思決定において気づかないうちに入り込んでくる。
システム１は定量的な判断に、特に確率の関わる問題に関して非常に不向きである。社会の中の複雑な現象に関する意思決定についてバイアスのある直感に流されずに、システム２を発揮して定量的に正確な分析に基づいて判断するには、多大な努力と数学と統計学の知識を必要とする。そして、その論理的な分析の帰結を多数の人に伝えるときにもまた、受け手のシステム１による干渉の影響を無視することができない。言葉の受け取り方や時系列の情報処理における重みづけについても、システム１はバイアスを持っている。正しい論理に基づいた最適な判断でも、伝え方が変われば異なるメッセージを送ってしまうことも起こる。最後の章で筆者は、バイアスの影響から逃れることは難しいとしながらも、自分のまたは周囲の人のシステム２を働かせて判断の誤りをできる限り回避するための効果的な方法を考える余地はあり、実際の組織の意思決定の過程は改善できると言及している。
今年に入ってから社会の状況は全く思いがけない形で大きく変わった。
今までにない不確実なリスクのもとで、不確実性のもとでの意思決定が普段より重大な意味を持っている。
我々が意思決定において、正しく考えているつもりでも論理的でない思考に影響される傾向について知ることは重要だ。それは様々な立場からの様々なレベルの言説を適切に読み取るためにも、自分自身がどのように考え、それをどのように伝えているかを振り返るためにも大事なことだ。</description>
    </item>
    
    <item>
      <title>「科学とモデル シミュレーションの哲学入門」</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/200305/</link>
      <pubDate>Thu, 05 Mar 2020 23:00:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/200305/</guid>
      <description>科学とモデル シミュレーションの哲学入門
マイケル・ワイズバーグ著、松王政浩訳　名古屋大学出版会
著者は科学哲学者だが、比較的科学者の方に歩み寄った内容で、厳密な（「意味論的な」）定義よりも科学者が実際の研究の営みの中で経験するモデリングに関わる様々な思考を分析する上での有用性を重視して書かれている。
そのため、おそらく通常の哲学書よりはかなり読みやすい本であり、普段この種の本に慣れていなくてもそれほど抵抗を感じずに読むことができた。
全部を理解できたわけではないが、重要な概念をいくつか知るきっかけになった。
以下は内容の抜粋。
 本書ではモデルを「構造」と「構造の解釈」からなるものとして説明する。「構造の解釈」がモデルの構造と現実の対象との間の関係性を特徴づける。
 本書ではモデルを「具象モデル」「数理モデル」「数値計算モデル」の3種類に分類する。「具象モデル」は物理的実体を用いたモデル、「数理モデル」は数式によって記述される。「数値計算モデル」は数学的に記述される遷移規則からなる。
 「具象モデル」の例としてダム建設の港湾部の水環境への影響を調べるための縮尺模型、「数理モデル」の例として個体数振動を説明する生態学のロトカ・ヴォルテラモデル、「数値計算モデル」の例としてマクロな人種毎の居住地分布が個人の行動の傾向の結果として生じることを説明するシェリングモデルが用いられている。  数理モデルと数値計算モデルの区別は必ずしも明確ではない。場合によってはどちらともとれるようなモデルがあるかもしれない。モデルの構造より、モデルが目的とするものの違いが重要だと説明されている。数理モデルは与えられた数式による記述のもとで系がとる状態の性質を知ることを目的とするのに対して、数値計算モデルはむしろ目的とする対象のある性質がどのような遷移規則によってもたらされるか知ることを目的とする。また数値計算モデルは必ずしも数式ではなく、条件分岐などを含むアルゴリズムとして記述されるものであり、コンピュータプログラムでの記述として実践される場合が多い。
 「シミュレーション」とは数理モデルの分析の一形態に位置づけられる。
 モデルの解釈は以下の4つの部分からなる。
 「割り当て」＝モデルの各要素と対象の各要素の対応付け 「範囲」＝不可分な現実の対象のうちモデルで表現している範囲の特定 「動的な忠実度基準」＝出力が現実に似ているか 「表象の忠実度基準」＝モデルの構造が現実に似ているか  興味のある単一の対象に応じた単一のモデルを用いるのが最も単純なモデリングの形態だが、実際の問題はもっと複雑で様々なモデリングがあり得る。その際に「理想化」という手続きが必要になる。理想化には以下の3種類がある。
 「ガリレイ的理想化」: 問題を扱いやすくするために現実とは整合しない要素を含める(例：摩擦を無視) 「ミニマリスト的理想化」: 最も単純に対象を説明できるような因果関係のみを表現 「多重モデルによる理想化」: 複数の異なる理想化に基づくモデルを並列させる  多重モデルは現実の現象が単一の原因に帰着させられるほど単純でなく、何を対象の範囲とすべきかも自明ではないようなときに有用である。異なる思想に基づく異なるモデルによって共通した結果が得られるとき、単一のモデルによる結果よりも強い主張といえる、というのが「ロバスト分析」の考え方である。
 ミニマリスト的理想化に関わる「何をもって説明したことになるのか」という問いに対しては、「説明とは現象の発生に差異を生むための因果的な筋立てを与えることである」とする「カイロス的見解」が引用されている。ただしあくまで複数あるうちの一つの見解としての紹介である。  モデルと対称との「類似性の説明」についての一章では、さまざまな尺度からのモデルと対象との適合性について一般的な数式による記述を試みている。「属性」（モデルの出力変数）と「メカニズム」（モデルの構造や遷移規則）の2つが別々の項として扱われる。また、比較は対称的ではなく、「現実の対象の属性のできるだけ多くをモデルが含む」ことに重きをおくか、「モデルの属性のできるだけ多くが現実と整合する」ことに重きをおくかは異なる。それぞれの項の重みづけはモデルの解釈に依存する。
 例えば「完全性」を理想とするモデルでは現実のメカニズムと要素の両方をできるだけ忠実に精密に再現することを目指すが、「ミニマリスト的理想化」に基づく因果の説明のためのモデルは「（モデルで仮定したメカニズムに基づく）モデルの属性が現実と整合する」ことや「モデルのメカニズムが現実に対応し余計なものを含まない」ことに重きを置く。   以下、考えたこと。
 「数理モデル」が力学系の方程式が与えられた時のアトラクタやその安定性などを調べる「演繹」に対応し、「数値計算モデル」が気体分子運動論のようにマクロな性質を導くためのミクロな原理を探求する「帰納」に対応する？
 気象予報モデルが「数理モデル」なのか「数値計算モデル」なのかをこの定義に従って明確に決めるのは難しいように思う。予測に使う場合は「既知の遷移規則の下で、ある初期値が与えられたときの未来の系の状態を知りたい」という問題になるので数理モデルとしての使い方になる。一方で、観測された大気化学種の分布からデータ同化を使って排出量を推定するような研究なら、数値計算モデルに分類される。
 上のように数理モデルとして気象予報モデルを解釈すると、「数値計算モデルは数理モデルとは異なり、プログラムの形をとり条件分岐や確率過程を含むアルゴリズムとして記述される」というような説明とは整合しない。したがって予報モデルの実践はやはり両者の要素を合わせもっていることになる。
 「説明とは差異をもたらす因果性である」という見解は経験的に納得しやすい。むしろ他にどのように異なる見解があるのか気になる。科学実験で「ある要素を除いたら現象が発生しなくなった、だから現象はその要素によって起こっていると説明できる」という論理は非常によく使われる。　 一般的な「多重モデル」（マルチモデル）の概念の導入は非常に役に立った。気象・気候予測においてよく使われる「マルチモデル」は特殊な使い方であり、ここで定義されるマルチモデルの性質と共通していないという点を認識しておくことは大事だ。
異なる気象予報モデルを比較しているといっても、大部分が同じような思想と同じような近似に基づいて構築された、同じような構造を持ったモデルである。格子構造や物理過程のパラメタ化の一部は大きく異なるかもしれないが、用いている基礎方程式や境界値はほとんど同じであり、その部分にはマルチモデルの利点はそれほど期待できない（＝同じ種類のバイアスがあるかもしれない）。
 ただし、気象予報でも異なる構造のマルチモデルが実践されている場合もある。インド気象局の夏季モンスーンの長期予報は統計モデルと全球モデルの両方を並列して用いている。アメリカの気候予測センターのMJOの予測も、MJO指数に基づくアナログなどの統計的予測と、複数の全球モデルのアンサンブル予報の両方を公開している（たいてい両者は一致していない）。
  本書で論じられていなかったが重要かもしれない要素をいくつか思いつく。
 科学者が物事の性質や因果関係を解釈するときに頭の中で思い描く「メンタルモデル」と呼ばれるものがあるが、本書の内容から説明できるか？
 実態として「多くの人が異なる目的で使うためのモデル」というものが存在する。特定の現象やメカニズムに重きを置くのではなく、むしろどの現象やメカニズムも十分に表現されており、興味に応じて使えるものであることが重視される。「完全性」を理想とするモデルに分類されるものに近い。
 実際の現場ではモデルの制作者と利用者が異なる場合が多い。そのため、そもそもモデルの構造も思想も共有することなく使ってしまうケースも多い。開発者が行ったモデルの解釈が理解されていないということは、モデルと現実の対象との比較評価を行うとき、比較の項の重みづけに必要な背景を持っていないということを意味する。特にモデルが大規模な複雑なものになればなるほど、モデル自体の理解は追いつかず、解釈の基準が素人的で単純なものになりがちな傾向がある。結果として、単純な問題のために不必要に複雑なモデルを使うという状況が起こり得る。
  </description>
    </item>
    
    <item>
      <title>今年の暖候期予報</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/200227/</link>
      <pubDate>Thu, 27 Feb 2020 23:00:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/200227/</guid>
      <description>2月26日に気象庁から今年の6～8月の気温と降水量についての暖候期予報が発表された。
http://www.jma.go.jp/jp/longfcst/000_1_20.html
また、同時期にTokyo Climate Centerからもアジア全体の今年の夏の気候についての長期予報の解説資料が出ている。
https://ds.data.jma.go.jp/tcc/tcc/products/model/monthly_discussion/latest.pdf
全国的に気温は「平年並みか高い」見込み、降水量は「ほぼ平年並み」とのこと。
長期予報では、モデルのプロダクトや解説資料を参考にどのような大規模場の特徴が偏差をもたらしているか考えることが、予報の不確かさを把握するためにも重要だ。
気象庁の解説資料では、今年は日本の夏の気候に関わるグローバルな気候場の特徴があまり明瞭でなく、解釈が難しいという印象だ。 ENSOは中立、IODはやや正よりの中立、アジアモンスーンの全体的な降水量もそれほど顕著な偏差ではない。
また、模式図の解説は「夏の前半」と「後半」を区別していたので、SSTや対流活動の偏差は夏季平均だけでなく一か月単位くらいでの推移が重要そうだ。 「夏の後半」でフィリピン沖（Nino.west）のSSTの正偏差の影響が出ると予想されており、これが高気圧の微妙な張り出しを通して全球的な温暖化とは別に高温偏差に寄与している成分と考えることができそうだ。ただしSSTの予想の不確かさの幅は大きい。
チベット高気圧は模式図に登場しなかったので、夏季平均では特徴が顕著でないということだろうか。
こういうときは相対的に季節内変動の重要性が高くなると考えられる。5月ごろになってSST偏差や、約一か月周期のMJOやモンスーンの季節内変動の予報がどうなっているか注目したい。
上記の資料は気象庁の全球アンサンブル予報システムに基づいている。モデルの予報値はTokyo Climate Centerのwebサイトで見られる。
http://ds.data.jma.go.jp/tcc/tcc/products/model/map/7mE/map1/zpcmap.php
他の機関のモデルによる長期予報も、マルチモデルアンサンブルを含め様々なプロダクトをweb上で見ることができる。情報量はとても充実している。 ただし、よほど訓練されてない限りは、web上でこうしたプロダクトを眺めるのみでは何か意義のある判断はできない（むしろできると考えてしまうのは危険だ）。 最低限の解釈の指針を示すためのテキストによる解説を見つけた方がよいだろう。
NWS Climate Prediction Center - North American Multi-Model Ensemble (NMME) forecasts
https://www.cpc.ncep.noaa.gov/products/international/nmme/nmme.shtml
ECMWF - Long range forecasts
https://www.ecmwf.int/en/forecasts/documentation-and-support/long-range</description>
    </item>
    
    <item>
      <title>大規模数値シミュレーションに関する考え</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/200224/</link>
      <pubDate>Mon, 24 Feb 2020 22:00:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/200224/</guid>
      <description>「モデルを回しているだけで研究していることになるのか？」というようなモヤモヤした疑問は学生のころから感じていた。 また、他の学生の感度実験の研究を見て、「あんなの線形応答と同じだろ、モデルを使わなくても分かっていたことじゃないか」と研究室の仲間と毒づいたりもした。
しかしこの種の問題は、モヤモヤした違和感は共有することができても、正確な言葉でうまく表現することが難しい。 かつて高名な気象学の先生が「モデルの研究には文化の香りがしない」というような批判をされたと聞いたが、それも言いたいことは良くわかるのだがやはり何を批判しているのかが明確でない。
原因の一つが語彙の不足にあるように思う。 日常的、もしくは研究現場で慣用的に用いている言葉は厳密な概念的な議論をするには語彙が足りず、多数の意味にとれる同じ語句が多すぎる。
例えば、ここでは「モデル」という言葉を現代の研究者の慣用に従って「離散化した基礎方程式に基づく大気海洋の大規模な数値シミュレーション」という意味で用いているが、本来は「モデル」といえば対象を分析するために概念化したものならどんなレベルのものでもあてはまる、非常に幅広い言葉である。
「理解する」とか「説明する」とかいう言葉もやはりあいまいだ。こういうことは言葉よりはむしろ感覚で共有している。「それで何が理解できたことになるのか？」という疑問や、「これは新しい理解を提示して意義がある」という感じは研究者の間で共有できるものだが、それを改めて概念にしたり、まして定量化しようと途端に難しくなる。
しかし、こうした難しさは本質的にそれが不可能であるからなのか、それとも単に言葉の厳密さを重視する社会科学の訓練を受けていないからだろうか？ 科学哲学の専門家によるきちんとした分析の助けを借りれば、日常的なモヤモヤをもっと説得力のある言葉で表現できるようになるだろうか？
そこで、2017年に刊行されたマイケル・ワイズバーグ氏による入門書の和訳「科学とモデル シミュレーションの哲学入門」を読んだ。
本の内容に基づいて考えたことは別にまとめることにして、読書前の自分の問題意識を下にメモしておく。
 実際の研究の現場ではかなりの部分において、「そのモデルを使うほどのことはないかもしれないが、とりあえず使ってみる」というノリで大規模シミュレーションを動かす状況がよく起こる。
 大気力学の研究室では、モデルの結果の「解釈」を重視する姿勢を強調して教えられた。理学としては重要な姿勢だと思うが、「解釈できるなら最初からシミュレーション要らないのでは」という疑問に答えるのは容易ではない。
人間の頭のメモリの容量はとても小さいので、頭で考えての解釈は必ず縮約された情報量で行われる（例えば大気大循環モデルによる数TBの出力データを用いてMJOの指数に対するコンポジットを計算して、主要な変動の大部分がMJOへの応答として説明されるという仮説を検証したりする）。しかし、どんなに大規模なシミュレーションの結果も結局そのような低次元の理解に落とし込むことになるのなら、最初から低次元の概念的なモデルで（もしくはその低次元の特徴を含む最小限のモデルで）シミュレーションすればよいのでは？ということになる。まじめに考えるなら、解釈のための次元縮約がつねに近似でしかなく、その次元での挙動も本当は系の細かい状態との相互作用に影響されるものであることを念頭に置いて大規模シミュレーションを行う、ということになる。理想はそうだが実際はそこまでの考慮が読み取れる研究ばかりとは限らない。
 「理解する」「解釈する」とか、「説明する」という概念は０か１ではなく、０と１の間の中間の値をとるものであり、ある理解よりも高次な別の理解というものがあり得るように思う。もしくは、ある理解を別の理解と比較するための軸は単一ではなく多次元かもしれない。
 現象の理解を目的とした理学的なシミュレーションだとこうした難しい議論になるが、工学的な（と分類してよいか分からないが）現象の理解はともかく予測をしたいという目的の場合にはもっと単純にシミュレーションが受け入れられているように思う。気象予報や気候予測がどちらに分類されるかは単純ではないが、何となくは、時間スケールが長く、不確かさが大きいほど、人間の（構造化した概念モデルに基づく）理解がより必要とされる傾向があるような気がする。長期予報に解説資料が必要であるように、また気候予測に「モデルの結果だから」にとどまらない詳細な説明が必要であるように。
 「シミュレーションは科学と呼べるのか」という哲学的な問いとはまた別の種類のものとして、「シミュレーションを行う研究者の日々の営みは実際どのくらい科学的な営みと呼べるのか」という現実的な（社会科学的な？）問いがあると思う。これは大学院の学生がシミュレーションの研究をすることは一般の科学的方法を身につける上で適切なのか、という重要な実際上の問題に関わる。
  </description>
    </item>
    
    <item>
      <title>フランス・ブレストの気候と天気</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/200228/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/200228/</guid>
      <description>海外出張に行くたびに、現地の気候や天気の基本的特徴を勉強したり、利用できる気象情報アプリについて調べるのが楽しみになっている。
ブレストの気候 参考：
meteoblue - climate(observed)
https://www.meteoblue.com/en/weather/historyclimate/climateobserved/brest_france_3030300
MeteoFrance - The climate in France
http://www.meteofrance.fr/climat-passe-et-futur/climat-en-france/le-climat-en-metropole#
 ブレストはフランスの北西端に位置し大西洋に面しているため、
典型的な海洋性気候の特徴を持つ 一年の寒暖差が小さく降水が多い。
山岳地域を除くとフランスでも最も降水量の多い地域である 冬の最高・最低気温は神戸とだいたい同じくらい 降水は冬に多くほとんどが雨。2月の平均降水日数は15日前後。
大西洋からの低気圧や前線の通過に伴って数日～約10日周期で推移する 海辺に位置しているためやや風が強い  フランスの気象予報ウェブサイト ヨーロッパの天気図 http://www.eurometeo.com/english/maps
MeteoFrance 天気予報 http://www.meteofrance.com/previsions-meteo-france/brest/29200
MeteoFrance - 地点ごとの降水短時間予報 5分ごとに更新 http://www.meteofrance.com/previsions-meteo-france/previsions-pluie/brest/29200
MeteoBlue - meteogram 7日間予報の時系列 https://www.meteoblue.com/en/weather/forecast/meteograms/brest_france_3030300
meteociel 各国の全球モデル・ヨーロッパ周辺の領域モデルの予報値 https://www.meteociel.fr/</description>
    </item>
    
    <item>
      <title>AIの専門分科会</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/191109/</link>
      <pubDate>Sat, 09 Nov 2019 01:00:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/191109/</guid>
      <description>　気象学会秋季大会では、「人工知能（AI）は気象学にブレイクスルーをもたらすか？」という専門分科会で発表する機会を頂いた。
実際の観測データへの適用例が多い中、Lorenz96モデルを用いた基礎研究という硬派な話題を提供することになったので、全体のバランスと多様性に少しは貢献しただろうか。
機械学習の研究では「実際そこまで複雑なことをする必要があるか？」という問題がついてくるものだが、自分の研究も現時点では問題の複雑さに応じたモデルの評価をするまでに至っていないので、次の機会までに改善したい。
AIという呼び方はあまり好きではないのいで「冗長性をもつノンパラメトリックな統計的推定」と言い換えて解釈しているが、他の手法に比べてどんな長所と短所があり、何に役立つのか、まだ明確な答えは見つけられるほどは勉強ができていない。
また、データ同化が一般的なデータ駆動型の機械学習の一種とみなせるのか、それとも一線を画した異なるものなのか、ということについてもまだ分からない。さしあたり、観測誤差を定量的に扱う（観測誤差と比較する対象としてのモデルの背景誤差を定量的に扱う、と言い換えることもできる）ことがデータ同化の本質のような気はしているが…
しかし現代のビッグデータ同化は果たして「観測とモデルの間の内挿」という描像にあてはまるだろうか。観測とモデルは対等だろうか。
機械学習の応用という分野は始まったばかりで、たくさんの試行錯誤を繰り返して足場を固めていく時期にあると思うが、いずれ次の段階が来ることだろう。数学的に定式化できる問題が一通り議論された後に残るのは、もっと扱いづらい、価値判断に関わる問題であるように思う。
例えば、何を優先して最適化するかの基準を誰が決めるのか、とか、
実験で裏付けられた物理法則の知識がなぜデータ駆動型の経験的近似より価値があるのか、その違いをどう定量化するのか、というような。
今まで何となくフィーリングで乗り切ってきたことを、改めて言葉で説明しようとすると難しい。
機械学習の普及によって、問題のプロセスを理解するための努力を省略して問題に答えが出せてしまう状況が生じたことで、理解することの意義を言葉で説明する必要性が生じてしまった。
今まで使ってなかった頭を使う気がして、新しい問題を考えている気になっても誰かがとっくに答えを出していることが後でわかったりして、かなり居心地が悪いのだが、とはいえ安全なところに逃げ込むわけにもいかない。
自分の研究もまだ発展途上だが、これからもいくつかの場所で発表と議論の機会があるのは有難いことで、議論のレベルをもっと上げていきたい。 </description>
    </item>
    
    <item>
      <title>国際HPCサマースクール</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/190715/</link>
      <pubDate>Mon, 15 Jul 2019 21:40:00 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/190715/</guid>
      <description>先週R-CCSで行われた国際HPCサマースクールに参加した。
各国の学生や研究者が集まり、5日間かけて大規模数値計算に関する技術の基礎を学ぶ。内容は並列計算、パフォーマンス評価、プロジェクト管理、機械学習、ビッグデータなど。
参加者は確か80人以上おり、計算科学という共通項はあるが医療から宇宙まで専門は幅広く分散していた。見たところ気象関係は自分だけだった。
毎日講義と実習が続き、忙しい5日間だった。
合間にはメンターセッションと呼ばれる時間があり、研究に限らず研究者としての生活に関わる全般的なこと、 例えばワークライフバランスや民間への就職などについて、それぞれ割り当てられた担当者に相談できるようになっていた。
このような面倒見の良さはこのサマースクールの特徴の一つのようだ。
夕方からは連日何かしらのソーシャルイベントがありみんなで食事をともにした。
こうした席で初対面の若者たちとコミュニケーションをとって関係を作ることもサマースクールの大事な目的の一つである。
日本人は一般的にこういうのが苦手で存在感がなくなりがちだ。大部分が言語の問題だが、単に経験が足りないという点もあるように思う。 日本の組織の中でのコミュニケーションのとり方に慣れていてもあまり役に立たない。
参加者の学生は普通の見た目をしているが、実際とても頭の回転の速い人たちで、
そこについていくのは大変だった。冗談を言うにもスペイン語の教養が要るとか…
その割にテニスよりはサッカーの方が話題にしやすかった。
インドから来た研究者の人には意外な話を聞かされた。
「日本の製造業の品質重視の姿勢は世界に誇るべきだ」「日本人は英語をあまり重視しないが、その代わりに日本語を通して文化が継承されていることは素晴らしい」とのこと。
現代のインドで英語とそれに基づいた教養ばかりがもてはやされ、古いものが軽視される現状があるという話だった。
高等教育を受けた人はほとんどが英語のみを使って生活しており、ヒンディー語は小学校で習ったきり使う機会もなく、大半の人が忘れてしまう。
ヒンディー語で生活している人と英語しか使わない人がはっきり分かれており、社会の分断が起きている。
「この10年でインドはすっかり変わってしまったが、自分は変わる前の姿が好きだ」といった。
ちょうど10年くらい前に自分がデリーに行った時は、都市の豊かな部分と混沌とした部分の両方を見たような気がする。
乱雑な路地や人力車や野良犬や牛を見て、この風景は何十年たっても変わらないに違いないと思ったことを覚えているが、今ごろどうなっているだろうか？</description>
    </item>
    
    <item>
      <title>LETKFの「L」</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/190609/</link>
      <pubDate>Sun, 09 Jun 2019 23:16:31 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/190609/</guid>
      <description>アンサンブルカルマンフィルタにおいて解析を局所的に行うということが、しばらくの間は何となく素直に納得できなかった。
最適な推定値を求めるといったときに、その「最適」の尺度として全体についての単一の尺度を使うのではなく、 領域の中の部分ごとに異なる複数の尺度を同時に使うという発想は自然なものだと思う。
そのおかげで、東京の予報を最適にするために京都の予報の精度を少し下げる必要があるというような状態は起こらない。
ただし、背景誤差の表現のためのアンサンブルはあくまで領域全体についての予報値であり、領域全体の都合に従った性質を持つはずで、それを 部分ごとにバラバラにしてそれぞれの部分ごとの都合に応じた異なる組み合わせ方をすることは、 手法としての一貫性を損なっているのではないかという疑問があった。
直感的には、WKB近似などと同じように「異なる複数の前提を使って都合よくいいとこ取りをしている」手法であるように思える。 ではその「いいとこ取り」が成り立つための都合のいい前提とは何か？
局所低次元性(Patil et al. 2001)という性質があるが、それと同時に、 「局所的な解析によってより高次元の表現ができる」と言われることもあるのがややこしい。
根拠とされているのは局所低次元性であるが、その背景には領域内の場の時間発展の複スケール性がある。
すなわち、予報をする領域を東西方向に適切な大きさの小領域に区切ったときに、それぞれの小領域の中でそれぞれ独立に摂動が成長する とみなすことができる部分が、大気の変動の大部分を占めているということである。
たとえば小領域の中での次の6時間の推移のしかたに分岐があって、同じような初期値からとりうる状態が2通りあるとしたら、 同様の小領域4つからなる全体のとりうる状態は16通りになる。
このような状態は、力学系の入門書で最初に教わる、系の複雑さを議論するためのLyapunov次元などの概念的なイメージとはかなり異なっている。
実際のところは、系がひとかたまりとして動くというよりは、 それぞれ勝手な都合で動く複数の系を集めてきて一つの系であるように見なしているという状態に近い。
この性質は必要なアンサンブルメンバーの数を考えるうえで大きな意味を持つ。
先の例だと、主要な摂動成長の構造が各領域で2通りずつあるとしたら、系全体では16通りの組み合わせがある。
もし系全体で一つの解析値を作るために同化を行うなら、起こりうる構造を表現するためにアンサンブルメンバーは少なくとも16個要ることになる。
解析を局所化する場合はどうか。16メンバーのアンサンブルがあっても、 その中で各領域で実際に違いをもたらすのは2種類の構造だけであり、他は重複している。もっと減らしてもよいはずである。
アンサンブルメンバーのうち2種類の構造を含んでいるものを見つけ出せればよいのだから、確率的なばらつきを考慮しても、 16個よりはずっと少ない数で十分に目的を達することができる。
これが、「局所的に低次元である」ことと同時に「解析の局所化によってアンサンブルメンバー数より高い次元の構造を表現できる」ことの種明かしである。 1000個の漢字を覚えるのは大変だが、同じ1000通りの違うものを表現するのに3つの数字の組を使えば10種類の数字を覚えるだけで済む、 と考えればわかりやすいかもしれない。 実際の状況では、局所低次元性が「ある程度」成り立つくらい局所的なふるまい方をしており、 なおかつ同時に「ある程度」系全体に及ぶような構造の予報期間内の変動も存在する、というような中間の状態にあることが想定される。
そのために、全体についての予報モデルの結果としてのアンサンブルメンバーの重ね合わせで解析値を表現できるとし（LETKFの&amp;rdquo;T&amp;rdquo;）、 ただしその重ね合わせ方は局所的にそれぞれ異なっていてもよいとする(LETKFの&amp;rdquo;L&amp;rdquo;)、という方法をとることができる。
個人的にはLETKFは洗練されたエレガントな手法であり、アンサンブルカルマンフィルタの完成形の一つであると思う。
実際に時空間分布する物理量を予測する気象のようなモデルでは、モデルの出力の目的や注目点が使う人によって様々であったりする。 全体の気圧配置を見たい人もいれば、ある地点の天気に注目する人もいるし、 3時間後の予報も24時間後の予報も同じくらい重要性をもって見られる。 実際の運用上で必要となる、全体と部分の柔軟な使い分けに対して、LETKFはLocalとTransformを両方備えていることによってうまく対応している手法であるように思う。</description>
    </item>
    
    <item>
      <title>ニューラルネットワークによる関数の近似</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/190520/</link>
      <pubDate>Mon, 20 May 2019 00:10:18 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/190520/</guid>
      <description>自分の勉強のためfortranで最も単純なニューラルネットワークを作った。
(2019/6/23 追記：TensorFlowがニューラルネットワークの仕組みをブラウザ上でインタラクティブに体感できるツールを提供している(https://playground.tensorflow.org) 。
以下に書いたような内容に近いことを扱っているが、もちろん、ずっと洗練されている。)
ニューラルネットワークを回帰問題に用いる場合、入力変数と出力変数の間の任意の関係を表現する、汎用的な近似器として用いることができるとされる。
関数形を何も措定せずに、非線形を含むどんな形の関数関係でも近似できるというのは、最初に聞いたときはとても違和感があった。 しかし、その仕組みを知ると、実際のところとても自然な方法であるとわかった。 自然というのは、人間の認識の仕方によく似ているということである。
最も簡単な、入力と出力の変数が1個ずつ(xとyとする)の場合を考えてみる。
下に適当に作ったxとyのデータを示す。この点の集まりからxとyの間の関係についての推定を行うことを考える。
データ  ぱっと見でこの図をどう捉えるか？ 仮に最小限の言葉で特徴を説明する必要があるとしたら、例えば次のような説明のしかたができると思われる。
- 左に山がある
- その山の右肩により小さな山がある
- その山の右側に大きな谷がある
もしくははサイクリングの行程表のように、左から右に進むときの標高の変化を表していると考えることにして、次のように書くこともできる。
- 初めに少し上り
- 長いゆるやかな下り
- 少し上り
- 急な短い下り
- しばらく平坦ののち、急な登り
いずれの場合も、多くの点からなる情報を少ない数の要素に分割して説明している。 基本的な要素は、前者の場合は山と谷、後者の場合は上りと下りからなる。 いずれにしても、図をぱっと見たときに人間の頭の中で最初に行われることは、 全体が大体いくつの要素からなり、それぞれ大きさや位置がどのくらいであるかを把握することだと思われる。
一方で、統計的なデータ解析も基本的に目指すことは同じである。すなわち多くの要素からなるデータの特徴を少ない言葉で記述することが目的である。 データ解析においてはどのように要素への分解を行っているだろうか。 単純な線形回帰の場合を考えてみる。
回帰問題は下のように書け、\(K\)個のパラメタ\(w_k\)および\(b\)を求める問題となる。 $$ y(x) = \sum_{k=1}^{K} w_k \sigma_k (x) +b $$ ここで\( \sigma_k \)は基底関数(basis function)であり、その選び方は問題に応じて様々である。
例として、多項式、フーリエ級数、ガウシアンの基底関数の組をそれぞれ下に示す。
基底関数  線形回帰問題では、基底関数（および定数）の線形結合で目的の関数を近似する。これを図にすると下のようになる。
左が入力データ\(x\)、右が出力データ\(y\)であり。中間の層の〇が基底関数、右側の線が係数\(w,\ b\)に対応する。
線形回帰 多項式の場合  6次までの多項式で回帰する場合、結果は下の図のようになる。 点線がそれぞれの基底関数であり（ただし便宜上縦にずらしている）、それらの総和が実線で表された回帰式となる。
6次の多項式による回帰  6個のフーリエ級数の場合は下の図のようになる。 フーリエ級数による回帰 
いずれの場合も図の右端付近で余計な曲線が入っており近似の精度が落ちている。これは基底関数が範囲全体にわたって変化するため、 右端の崖のような局所的な特徴が表現しづらいためである。</description>
    </item>
    
    <item>
      <title>Eqntest</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/eqntest/</link>
      <pubDate>Sat, 11 May 2019 14:31:11 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/eqntest/</guid>
      <description>時系列モデル
$$ {\bf x}{t+1}={bf Mx{t} $$
に従う変数 \({\bf x}\) を時刻 \(t+1\) で推定する。 ここではモデルが完全であると考えて時間発展に伴う誤差は無視する。 観測は ${\bf y}$ で、 ${\bf x}$ とは異なる次元を持ち（より少ない場合が多い）、次の線形関係を持つ。
$$ {\bf y}={\bf Hx} $$
考えている時刻 $t+1$ の観測のみ推定に用いるとする
モデルの予報値を $x_{t+1}^f$ と観測値 $y$ はそれぞれ誤差をもつ。真の値 ${\bf x}_{t+1}^t$ を措定すると、誤差は次のように表される。
$$ {\bf x}^f = {\bf x}^t + {\bf \epsilon}^f $$ $$ {\bf y} = {\bf Hx}^t + {\bf \epsilon}^o $$</description>
    </item>
    
    <item>
      <title>好奇心</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/190422/</link>
      <pubDate>Mon, 22 Apr 2019 02:10:11 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/190422/</guid>
      <description>先日、とある集まりで、年代も職業もそれぞれ違った十数人の初対面の人の前で自分の仕事について話す機会があった。
自己紹介をして、気象を研究している研究者です、というと、そこにみんなすごく食いついてきた。まるで珍しい動物を見つけたときみたいな好奇心いっぱいな様子で、どんな研究をしているの、一番面白いのはどんなことなの、どうしてその道に進もうと思ったの、といった質問を浴びせてきた。
このような状況は学生のときからある程度慣れていた。
旅先で、またはバイト先の共同生活の中で、出身も経歴も違う同世代の人たちと接することが多かった。 学内のサークルのような均質な場では意識しないような、外から見た東大生という姿を良くも悪くも思い知らされる経験だった。 大学に行かずに働いている人、大学生でも就職のためと割り切って通っているだけで社会の中で別のところに人生経験の場を求めてきた人、転職してきた人、さまざまな経歴の人がいた。 そうした人たちは、自分が普段見ていた周りの学生に比べて、居心地のいい肩書に甘えたところがない分、個人としての意識がよほどしっかりしているように思えた。
彼らから見て東大の理学部の学生は異質な存在として受け取られることも理解できることだった。 自分の行かなかった大学に行けている人、としての期待と、大学に行ってるのに何でそんなに世間を知らないんだ、という失望の微妙な入り混じった感情。 それを背景としたある種のステレオタイプの通りの振る舞いをしてくれることへの期待。
みんなで話をしている中で、研究分野についての話を求められるときもあったが、自分はそれが苦手だった。 どうしても研究の話を出すと、その場が生真面目な雰囲気になってしまうからだ。 テレビで人気の芸人が喋っているときに、いきなり池上彰が登場して解説を始めたような感じになる。 それまでの和やかな話の流れを止めてしまったようで、きまりの悪い感じがする。 しかしどうやらそれも含めて期待通りの反応のようだった。「融通きかない東大生がまた何か言ってるよ」みたいなネタとして。 それで場が成り立つならそれもいいかと思って段々開き直るようになった。しかしあまり良い気分ではなかった。
そんな経験があったので、普通に淡々と話すとまた退屈させてしまうと思って、今回は少しアドリブを加えることにした。 気象の研究のきっかけの話から脱線させて富士山の測候所の話をして、新田次郎原作の漫画の話をして、その中で登場する雪の結晶の話をしようとして。
そしたら、「そういうのじゃなくて、普通に研究の話が聞きたいの」とたしなめられた。
池上彰の解説みたいな話し方でよかったのだ。
普通に気象について知りたがっていた人たちだった。興味はあっても普段自分がそこまで時間をとって深く考えることができないことを、代わりに職業として毎日追求してくれている人に対しての、素朴な興味からの質問だったのだ。
どうやら今まで少し斜に構えすぎていたのかもしれない。</description>
    </item>
    
    <item>
      <title>虎の絵の話</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/190411/</link>
      <pubDate>Thu, 11 Apr 2019 00:57:18 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/190411/</guid>
      <description>最近の話題の関連で、絵描きの物の見方についての大学教授による記事が目に入った。
写真は視界に入るものを均等に投影している（カメラの物理的な特性による限界はあるが）のに対し、絵による表現には対象への主観的な注目が含まれる。どの対象に注目してどのように捉えるのかによって見え方が変わる。そこに技術の良しあしがあり個性が出る、ということだそうだ。
確かに目で見た風景の見え方が写真のようではないことは普段から体験できる。丹沢や奥多摩の山に登って見える富士山の大きさには圧倒的なものがあるが、撮った写真を家に帰って見てもその感じは伝わらない。その「圧倒的な大きさの感じ」は単なる画像の情報だけでなく無意識に心の中で起こる認識の加工の結果として生まれるものだからだ。絵を描くときは風景写真とは異なり、そのような主観的な印象も絵の中に再現することになる。
気象学においてデータ同化は客観解析とも呼ばれるが、それに対して主観解析という概念がある。
解析とは一般に断片的な情報から整合的な全体像を作るための作業のことを呼んでいる。客観解析の場合の全体像は様々な変数の3次元的な分布に相当し、大容量の数値データとして保存されるが、主観解析では頭の中に現象を把握するための全体像を描くことを目的とする。
数値計算がまだ使えず観測も今よりもずっと少なく断片的であった時代には主観解析こそが解析であり（客観解析の発想はあるにはあったが単純な基底関数を使ったフィッティングのようなものでしかなかった）、手作業で等圧線を引くために観測点の間の補完を頭の中で行っていた。
現代の天気図解析と呼ばれているものは少し意味合いが異なり、6時間または12時間ごとに更新されるモデルの解析値や予報値から生成した各高度の天気図から重要な特徴を読み取って把握する作業のことである。つまり目的は物理量の推定ではなく、推定値はすでに客観解析で得られているので、その大量のデータを解釈することにある。 頭で考えるには格子データではなく、低気圧や前線の位置や等圧線の形状といった概念的な認識が必要になる。 経験を積むことで3次元的な構造や時間的な推移も含めた整合性を考慮したり、予測の不確定性の高い状況を見分けたりできるようになると思われるが、 より重要なのは、主観的な価値判断を加味した解析であるという点であろう。限られた時間と脳の記憶容量の中で注目すべき特徴と適切な概念モデルを選択しなければならない。 データ同化とは違って完全に客観的な重みづけを行うことができない。
もちろん気象予報は科学の一部であって芸術家とは目指す方向が違うが、 出力データを目で見て把握するときに主観的な判断の巧拙がどこかで必ず入ってくることは時々思い出した方がよさそうだ。</description>
    </item>
    
    <item>
      <title>ディープ・シンキング 人工知能の思考を読む</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/190404/</link>
      <pubDate>Thu, 04 Apr 2019 08:20:49 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/190404/</guid>
      <description>チェスの元グランドマスター、ガルリ・カスパロフ氏による書き下ろしの日本語訳。
カスパロフ氏は1997年にIBMのディープブルーとの2回目の番勝負に敗れ、初めてコンピュータに敗れた人間のグランドマスターとして歴史に残ることとなった。
チェスの世界でコンピュータが人間に勝利したというニュースは世界的な話題となり日本にも届いた。ちょうど羽生善治が七冠を達成して約1年後のことで、将棋がNHKの連続ドラマの題材になり、どの小学校でも紙の駒で遊ぶ子供たちがいた頃だった。その世代が大人になった2013年に今度は将棋の世界でもコンピュータとの本格的な衝突が起こることになるのだが、そのような状況は当時はまだ遠い未来のように思えた。インターネットや携帯電話は今ほど身近ではなかった。コンピュータの性能は今よりもはるかに低く、とても扱いづらかった。そのような20世紀に将棋や囲碁に比べて20年近く先んじて起こった出来事は、したがって、実際のところ決して巧妙でスマートなものではなかった。
コンピュータにとって得意な思考と苦手な思考というものがはっきりと存在する。単純な大量の記憶や演算の繰り返しは得意である代わりに、構造的な認識を柔軟に使い分けることはとても苦手だ。前後の手のつながりを認識できずに無意味な繰り返しをしたり、人間にとっては当たり前で初級者でもわかる駒の配置の良し悪しを判断できなかったりする。
その得意な部分を徹底的に押し進めるか、それとも弱点を克服する方法を探すか、コンピュータのチェスプログラムの開発には2通リの方針があった。言い換えれば、コンピュータプログラムをさらに極端に人間的でない姿にするか、できるだけ人間の姿に近づようとするかの選択ともいえる。人工知能の研究に人間の頭脳の働きの秘密を解明する手がかりを見出そうとする人たちや、チェスに人生の様々な神秘を重ね合わせてきた人たちは、後者こそが本当の最強のチェスプログラムへの道であると信じたかった。しかし20世紀の終わりに人間のグランドマスターを倒すという明確な目的のもとでは、前者の方針が明らかに成功していた。圧倒的な量の力が問題を解決した。それは当面の問題がチェスの解明ではなく、人間のチェスプレーヤーの尊厳へのリスペクトでもなく、勝つことだったからだ。
ディープブルーはとてもぎこちない姿をしていた。まず第一にマシンの動作それ自体が不安定で、対局中に停止して再起動を必要とすることも起こった。その指し手からはコンピュータらしさを隠しようがなかった。不自然な序盤戦で損をすることや、柔軟性を欠いた評価基準によって簡単に罠にはまってしまうような、コンピュータ特有の不格好な弱点は他のソフトと変わらなかった。その弱点を的確に突かれた対局では敗れた。その代わりに、圧倒的な読みの量による中終盤の正確さでは相手を上回り動揺させた。盤勝負全体としての内容は一方的ではなくとても際どいものだった。それでも、ディープブルーは当時できうる最大の努力のもとで勝利した。勝つ可能性を最大にする目的のもとで行われた開発によってなりふり構わずに勝ち取ったものだった（その「なりふり構わず」の中には開発元であり興業の主催者でもあったIBMによる様々な盤外の戦略も含まれていた、ということをカスパロフ氏は仄めかしている）。
カスパロフ氏は現在までチェスの元グランドマスターとして、自身の経験をもとにして人工知能と人間の知能や社会についての様々な議論に積極的に参加して大きな役割を果たしてきている。氏の語る創造性や人工知能との関わり方についての提言はとてもシンプルで多くの分野の直面する問題に共通するものだ。
2013年に将棋の、2016年には囲碁のプロ棋士が大舞台で初めてソフトに敗れた。現代のソフトはインターネット上の巨大なコミュニティの中で洗練された最新の強化学習の技術を駆使した巧妙なもので、ディープブルーの時代の数々の弱点を量だけではなく質的な意味でも克服してきている。すなわち、以前よりずっと人間と見分けのつかない姿をしている。それでも、人間の違いが不明瞭になったところで、人工知能の思考に関する問題の本質はそれほど変化していないことだろうと思う。
コンピュータのデータベースが導き出す序盤の最善手をただ記憶するだけでは勝率は一時的に上がっても、チェスが上達したことにはならない。変化に対応でき、自分で新しい手を考えだす能力を身につけるには、その手の意味を理解することが必要なのだ。では意味を理解するとはどういうことなのか？ではそれをプログラムの言葉で定義できれば、人間と同じような創造性を持たせることができることになるのか？当時から繰り返されてきた問いかけは今も続いている。
カスパロフ氏の1997年のゲームは、人間とコンピュータの双方が未知の相手と向き合うためになりふり構わない姿をさらしていた時代のものであるために、人工知能の登場にかかわるさまざまな問題を、今よりもずっとわかりやすい形で表していたように思う。
この本のハイライトはカスパロフ氏自身がディープブルーを相手に行った1996年と1997年の2回の番勝負の対局の内容を解説している部分にある。当事者であるからこそ書ける圧倒的な臨場感と、かつチェスの経験がない読者にも伝わるような明快な表現で、それぞれの対局における局面推移の特徴と思考の過程を記している。その部分を読むだけでもチェスの盤面に表れる景色の多様さや、競技としての身体的精神的な要素の複雑さや、定跡の背景にある数多くのプレーヤーの重ねてきた歴史の長さに触れることができる。</description>
    </item>
    
    <item>
      <title>はじめに</title>
      <link>https://aamemiya.github.io/webpage_aamemiya/jp/post/about/</link>
      <pubDate>Mon, 01 Apr 2019 23:14:58 +0900</pubDate>
      
      <guid>https://aamemiya.github.io/webpage_aamemiya/jp/post/about/</guid>
      <description>しばらく練習用に公開します。
研究に関連することで、でも普段の研究からは少しわき道にそれたことを書くような場所にしようと思います。</description>
    </item>
    
  </channel>
</rss>